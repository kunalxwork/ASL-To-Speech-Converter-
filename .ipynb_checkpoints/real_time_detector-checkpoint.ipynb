{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "41f4ac74",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking audio cache...\n",
      "Audio cache complete.\n",
      "Loading TFLite model from model/keypoint_classifier/keypoint_classifier.tflite...\n",
      "TFLite model loaded successfully!\n",
      "Model is 8-bit quantized.\n",
      "Final Sentence: EKEGAHEECDDE\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import threading\n",
    "from gtts import gTTS\n",
    "import pygame  # <--- NEW IMPORT\n",
    "\n",
    "# --- Configuration ---\n",
    "TFLITE_MODEL_PATH = 'model/keypoint_classifier/keypoint_classifier.tflite'\n",
    "NUM_CLASSES = 26\n",
    "CONFIDENCE_THRESHOLD = 0.10\n",
    "FRAMES_TO_SAMPLE = 15\n",
    "\n",
    "# --- Audio Caching ---\n",
    "AUDIO_CACHE_DIR = \"audio_cache\"\n",
    "os.makedirs(AUDIO_CACHE_DIR, exist_ok=True)\n",
    "print(\"Checking audio cache...\")\n",
    "for i in range(NUM_CLASSES):\n",
    "    letter = chr(ord('A') + i)\n",
    "    audio_file = os.path.join(AUDIO_CACHE_DIR, f\"{letter}.mp3\")\n",
    "    if not os.path.exists(audio_file):\n",
    "        print(f\"Creating audio for: {letter}\")\n",
    "        tts = gTTS(text=letter, lang='en')\n",
    "        tts.save(audio_file)\n",
    "print(\"Audio cache complete.\")\n",
    "\n",
    "# --- NEW Speak Function (using pygame) ---\n",
    "def speak(letter):\n",
    "    try:\n",
    "        audio_file = os.path.abspath(os.path.join(AUDIO_CACHE_DIR, f\"{letter}.mp3\"))\n",
    "        if os.path.exists(audio_file):\n",
    "            # pygame.mixer.Sound() loads the file and plays it\n",
    "            pygame.mixer.Sound(audio_file).play()\n",
    "        else:\n",
    "            print(f\"Error: Missing audio file for {letter}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error playing sound: {e}\")\n",
    "\n",
    "# --- Load the TFLite Model ---\n",
    "print(f\"Loading TFLite model from {TFLITE_MODEL_PATH}...\")\n",
    "interpreter = tf.lite.Interpreter(model_path=TFLITE_MODEL_PATH)\n",
    "interpreter.allocate_tensors()\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "print(\"TFLite model loaded successfully!\")\n",
    "\n",
    "IS_QUANTIZED = input_details[0]['dtype'] == np.int8\n",
    "if IS_QUANTIZED:\n",
    "    print(\"Model is 8-bit quantized.\")\n",
    "\n",
    "# --- Create Label Map ---\n",
    "label_map = [chr(ord('A') + i) for i in range(NUM_CLASSES)]\n",
    "\n",
    "# --- MediaPipe Hand Setup ---\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "hands = mp_hands.Hands(\n",
    "    static_image_mode=False,\n",
    "    max_num_hands=1,\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5\n",
    ")\n",
    "\n",
    "# --- Normalization Function ---\n",
    "def normalize_landmarks(landmarks, image_width, image_height):\n",
    "    landmark_array = np.empty((21, 2))\n",
    "    for i, landmark in enumerate(landmarks.landmark):\n",
    "        landmark_array[i] = [landmark.x * image_width, landmark.y * image_height]\n",
    "    relative_landmarks = landmark_array - landmark_array[0]\n",
    "    flattened_landmarks = relative_landmarks.flatten()\n",
    "    max_val = np.max(np.abs(flattened_landmarks))\n",
    "    if max_val == 0:\n",
    "        return None\n",
    "    normalized_landmarks = flattened_landmarks / max_val\n",
    "    return normalized_landmarks\n",
    "\n",
    "def draw_hand(image, landmarks):\n",
    "    mp_drawing.draw_landmarks(\n",
    "        image, landmarks, mp_hands.HAND_CONNECTIONS,\n",
    "        mp_drawing.DrawingSpec(color=(121, 22, 76), thickness=2, circle_radius=4),\n",
    "        mp_drawing.DrawingSpec(color=(250, 44, 250), thickness=2, circle_radius=2)\n",
    "    )\n",
    "\n",
    "def main():\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    prev_time = 0\n",
    "    \n",
    "    # --- NEW: Initialize pygame mixer ---\n",
    "    pygame.mixer.init()\n",
    "    # ------------------------------------\n",
    "    \n",
    "    sentence = \"\"\n",
    "    current_letter = \"\"\n",
    "    last_spoken_letter = \"\"\n",
    "    frame_count = 0\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "            \n",
    "        frame = cv2.flip(frame, 1)\n",
    "        frame_height, frame_width, _ = frame.shape\n",
    "        \n",
    "        image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = hands.process(image_rgb)\n",
    "        \n",
    "        prediction_text = \"No hand detected\"\n",
    "        \n",
    "        if results.multi_hand_landmarks:\n",
    "            hand_landmarks = results.multi_hand_landmarks[0]\n",
    "            draw_hand(frame, hand_landmarks)\n",
    "            keypoints = normalize_landmarks(hand_landmarks, frame_width, frame_height)\n",
    "            \n",
    "            if keypoints is not None:\n",
    "                model_input = np.array([keypoints], dtype=np.float32)\n",
    "\n",
    "                if IS_QUANTIZED:\n",
    "                    input_scale, input_zero_point = input_details[0]['quantization']\n",
    "                    model_input = (model_input / input_scale) + input_zero_point\n",
    "                    model_input = model_input.astype(np.int8)\n",
    "\n",
    "                interpreter.set_tensor(input_details[0]['index'], model_input)\n",
    "                interpreter.invoke()\n",
    "                prediction = interpreter.get_tensor(output_details[0]['index'])\n",
    "                \n",
    "                if IS_QUANTIZED:\n",
    "                    output_scale, output_zero_point = output_details[0]['quantization']\n",
    "                    prediction = (prediction.astype(np.float32) - output_zero_point) * output_scale\n",
    "                \n",
    "                predicted_class_id = np.argmax(prediction[0])\n",
    "                confidence = np.max(prediction[0])\n",
    "                \n",
    "                if confidence > CONFIDENCE_THRESHOLD:\n",
    "                    predicted_letter = label_map[predicted_class_id]\n",
    "                    prediction_text = f\"Prediction: {predicted_letter} (Conf: {confidence:.2f})\"\n",
    "                    \n",
    "                    if predicted_letter != current_letter:\n",
    "                        current_letter = predicted_letter\n",
    "                        frame_count = 0\n",
    "                    else:\n",
    "                        frame_count += 1\n",
    "                        \n",
    "                    if frame_count == FRAMES_TO_SAMPLE:\n",
    "                        if current_letter != last_spoken_letter:\n",
    "                            sentence += current_letter\n",
    "                            last_spoken_letter = current_letter\n",
    "                            # Still use a thread to be safe\n",
    "                            threading.Thread(target=speak, args=(current_letter,), daemon=True).start()\n",
    "                            \n",
    "                else: \n",
    "                    prediction_text = \"Low Confidence\"\n",
    "                    current_letter = \"\"\n",
    "                    frame_count = 0\n",
    "                    \n",
    "            else:\n",
    "                prediction_text = \"Hand detected, but normalization failed\"\n",
    "                    \n",
    "        else: \n",
    "            current_letter = \"\"\n",
    "            frame_count = 0\n",
    "            last_spoken_letter = \"\" \n",
    "        \n",
    "        curr_time = time.time()\n",
    "        fps = 1 / (curr_time - prev_time)\n",
    "        prev_time = curr_time\n",
    "        \n",
    "        cv2.putText(frame, prediction_text, (10, 30), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "        cv2.putText(frame, f\"FPS: {int(fps)}\", (frame_width - 150, 30), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "        \n",
    "        cv2.rectangle(frame, (0, frame_height - 50), (frame_width, frame_height), (0, 0, 0), -1)\n",
    "        cv2.putText(frame, f\"Sentence: {sentence}\", (10, frame_height - 15), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "        \n",
    "        cv2.imshow('ASL Keypoint Detection (TFLite)', frame)\n",
    "        \n",
    "        if cv2.waitKey(5) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    pygame.mixer.quit() # <-- NEW: Quit pygame\n",
    "    print(f\"Final Sentence: {sentence}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe9203b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pygame\n",
      "  Downloading pygame-2.6.1-cp310-cp310-win_amd64.whl (10.6 MB)\n",
      "     --------------------------------------- 10.6/10.6 MB 11.1 MB/s eta 0:00:00\n",
      "Installing collected packages: pygame\n",
      "Successfully installed pygame-2.6.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: There was an error checking the latest version of pip.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9d9f99",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
